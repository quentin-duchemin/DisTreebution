{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ad34444-2b98-4408-a0ae-35f603a6ed27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import pandas as pd\n",
    "import random\n",
    "import scipy\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91246bf2-d429-4eb7-a723-6a584a749775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/mydata/watres/quentin/PinballRT/')\n",
    "from UQ.UQ import UQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058af693-4adb-4a76-9241-d4a5da3af06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def crps_from_quantiles(quantiles, tau, y):\n",
    "    \"\"\"\n",
    "    Compute CRPS from predicted quantiles.\n",
    "    \n",
    "    Parameters:\n",
    "    - quantiles: List or numpy array of predicted quantiles.\n",
    "    - tau: List or numpy array of corresponding quantile levels (e.g., [0.1, 0.2, ..., 0.9]).\n",
    "    - y: The observed value.\n",
    "    \n",
    "    Returns:\n",
    "    - crps: The computed CRPS score.\n",
    "    \"\"\"\n",
    "    quantiles = np.array(quantiles)\n",
    "    tau = np.array(tau)\n",
    "    \n",
    "    # Compute the absolute errors\n",
    "    errors = np.abs(quantiles - y)\n",
    "    \n",
    "    # Compute the weights as differences in tau levels\n",
    "    weights = np.diff(np.insert(tau, 0, 0))  # Add 0 at the beginning for correct differences\n",
    "    \n",
    "    # Compute weighted sum\n",
    "    crps = np.sum(weights * errors)\n",
    "    \n",
    "    return crps\n",
    "\n",
    "\n",
    "def compute_crps(sample2predset, y_test, ls_q):\n",
    "    res = 0\n",
    "    for i, ytesti in enumerate(y_test):\n",
    "        res += crps_from_quantiles([sample2predset[iq][i] for iq in range(len(ls_q))], ls_q, ytesti) / len(y_test)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03635e6-576d-4db5-9f81-af1c3f420b4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ls_q = [0.1*i for i in range(1,10)]\n",
    "ls_q = [0.05 * i for i in range(1, 20)]\n",
    "#datasets = ['abalone',  'gas_turbine', 'combined_cycle_power_plant', 'red_wine', 'white_wine']\n",
    "datasets = ['abalone',  'gas_turbine', 'combined_cycle_power_plant', 'red_wine','white_wine']\n",
    "\n",
    "nbites = 27\n",
    "comple = ''\n",
    "lsntrain = [1000]\n",
    "dataset2SKLEARNerrors = {dataset : np.zeros((nbites,len(lsntrain))) for dataset in datasets}\n",
    "dataset2QNNerrors = {dataset : np.zeros((nbites,len(lsntrain))) for dataset in datasets}\n",
    "dataset2QRFerrors = {dataset : np.zeros((nbites,len(lsntrain))) for dataset in datasets}\n",
    "dataset2PQRTerrors = {dataset : np.zeros((nbites,len(lsntrain))) for dataset in datasets}\n",
    "dataset2PMQRTerrors = {dataset : np.zeros((nbites,len(lsntrain))) for dataset in datasets}\n",
    "dataset2PMQRT01errors = {dataset : np.zeros((nbites,len(lsntrain))) for dataset in datasets}\n",
    "dataset2PMQRT05errors = {dataset : np.zeros((nbites,len(lsntrain))) for dataset in datasets}\n",
    "dataset2CRPSRTerrors = {dataset : np.zeros((nbites,len(lsntrain))) for dataset in datasets}\n",
    "dataset2CRPSRTAVGerrors = {dataset : np.zeros((nbites,len(lsntrain))) for dataset in datasets}\n",
    "dataset2CRPSRT200errors = {dataset : np.zeros((nbites,len(lsntrain))) for dataset in datasets}\n",
    "dataset2CRPSRTAVG200errors = {dataset : np.zeros((nbites,len(lsntrain))) for dataset in datasets}\n",
    "\n",
    "root = '/mydata/watres/quentin/PinballRT/EXPE_FINAL/'\n",
    "\n",
    "\n",
    "for name_dataset in datasets:\n",
    "    for ite in range(1,nbites):\n",
    "        print('ITE ', ite)\n",
    "        print('\\n')\n",
    "        for i_ntrain, ntrain in enumerate(lsntrain):\n",
    "            print('Ntrain: ', ntrain)\n",
    "\n",
    "            y_test = np.load('sklearn_linear_new/{0}_{1}_{2}_y_test.npy'.format(ntrain, name_dataset, ite))\n",
    "            with open(root+'sklearn_linear/{0}_{1}_{2}_sample2predset.pkl'.format(ntrain, name_dataset, ite), 'rb') as handle:\n",
    "                sample2predset = pickle.load(handle)\n",
    "\n",
    "            dataset2SKLEARNerrors[name_dataset][ite,i_ntrain] = compute_crps(sample2predset, y_test, ls_q)\n",
    "\n",
    "\n",
    "\n",
    "            with open(root+'qrf_new/{0}_{1}_{2}_sample2predset.pkl'.format(ntrain, name_dataset, ite), 'rb') as handle:\n",
    "                sample2predset = pickle.load(handle)\n",
    "            dataset2QRFerrors[name_dataset][ite,i_ntrain] = compute_crps(sample2predset, y_test, ls_q)\n",
    "\n",
    "            with open(root+'crpsrt_new/{0}_{1}_{2}_sample2predset.pkl'.format(ntrain, name_dataset, ite), 'rb') as handle:\n",
    "                sample2predset = pickle.load(handle) \n",
    "            dataset2CRPSRTerrors[name_dataset][ite,i_ntrain] = compute_crps(sample2predset, y_test, ls_q)\n",
    "\n",
    "\n",
    "            with open(root+'pmqrt_01_new/{0}_{1}_{2}_sample2predset.pkl'.format(ntrain, name_dataset, ite), 'rb') as handle:\n",
    "                sample2predset = pickle.load(handle) \n",
    "            dataset2PMQRT01errors[name_dataset][ite,i_ntrain] = compute_crps(sample2predset, y_test, ls_q)\n",
    "\n",
    "            with open(root+'pmqrt_05_new/{0}_{1}_{2}_sample2predset.pkl'.format(ntrain, name_dataset, ite), 'rb') as handle:\n",
    "                sample2predset = pickle.load(handle)\n",
    "            dataset2PMQRT05errors[name_dataset][ite,i_ntrain] = compute_crps(sample2predset, y_test, ls_q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0b376c-09f1-43f4-9402-42ae53576916",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_q = np.array(ls_q)\n",
    "for name_dataset in datasets:\n",
    "    print(name_dataset)\n",
    "    x = dataset2SKLEARNerrors[name_dataset][:,0]   \n",
    "    print('SKLEARN', np.mean(x), np.std(x))\n",
    "    x = dataset2QRFerrors[name_dataset][:,0]   \n",
    "    print('QRF', np.mean(x), np.std(x))\n",
    "    x = dataset2PMQRT01errors[name_dataset][:,0]   \n",
    "    print('PMQRT01', np.mean(x), np.std(x))\n",
    "    x = dataset2PMQRT05errors[name_dataset][:,0]\n",
    "    print('PMQRT05', np.mean(x), np.std(x))\n",
    "    x = dataset2PMQRT05errors[name_dataset][:,0]   \n",
    "    print('CRPS-RT', np.mean(x), np.std(x))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f649c0-ee8e-4ccb-9b1e-e104f6f859e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
